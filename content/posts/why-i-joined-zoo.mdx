---
title: 'Why I joined Zoo'
excerpt: |
    Hard problems, smart people, and work of actual importance.
coverImage: '/documentation-assets/zoo-banner.png'
date: '2025-03-10'
author:
    name: Nick McCleery
    picture: '/documentation-assets/nickmccleery.jpg'
ogImage:
    url: 'meta-images/why-i-joined-zoo.jpg'
---

_About the author_

This is my first post since joining Zoo, so before I dive into my motivation for joining the team, I want to provide some personal background—mostly for the benefit of any mechanical engineers arriving here, wondering whether a software startup might have any real appreciation for the problems that they face.

My professional experience now crosses over into other realms, but I studied Mechanical and Manufacturing Engineering at university, and I began my career as a mechanical engineer in Formula One. Over the course of seven seasons, and across both powertrain and chassis development, I butted up against a pretty broad range of engineering challenges.

Though most of my time was spent on 'performance development'—crunching numbers, developing analysis tools, designing experiments, running rig tests, and performing simulation studies—I’ve also devised procedures for inspecting components, overseen the installation of imaging equipment, designed tools to support build, and served time as a mechanical designer. That design experience covers everything from the most minor washer chamfer detail through to wholesale redesign of big chunks of critical systems.

Since then, I've worked as a signal processing engineer in the biomedical space, a software engineer in both quantitative finance and defense, and founded and run an ill-fated engineering collaboration startup. I care deeply about engineering tooling, about improving engineering productivity, and about empowering engineers to improve our future.

_Nomenclature_

At the risk of upsetting software colleagues current and former, I should point out that when I use the term _engineering_ here, I'm generally referring to the physical disciplines: mechanical, aerospace, civil, structural, electrical etc.


----


## On the importance of engineering

This is paraphrasing from a presentation I delivered a couple of years ago, but worth repeating: engineering is of critical importance to our success as a species. Almost every man-made object you ever encounter is the product of an engineer's efforts.

Without engineering, we would not only have to forego cars and airplanes, but almost the entirety of humanity's tech tree. We would not have central heating or air-conditioning, roads or airports, apartment buildings, running water, sanitation, modern medicine, or mechanized agriculture. Both our way of life and our lives themselves depend on our ability to _make things_. 

## Why our design tools matter

We have been making things, and making tools, for as long as our species has walked the earth. The tools we use shape our environment, our behavior, and our way of life. Every advance in the capability of our tools yields an advance in what we can do with them.

## A brief history of post-Renaissance design tools

Focusing on engineering technology that has been developed in modernity (sorry Vitruvius), I see around twenty key developments between John Napier's invention of the logarithm and our current CAE suites.

![timeline](/documentation-assets/why-i-joined-zoo/engineering_tools_timeline.png)

If we group these development by decade, an interesting phenomenon emerges. The plot below shows relatively infrequent developments as we move from Napier to WW2. 

The post-war period, however, tells a different story. Driven by the semiconductor revolution, the 1970s is a golden era for engineering design tools. Between 1970 and 1978, we saw the first incarnations of ANSYS, NASTRAN, CATIA, ABAQUS, Parasolid, and NX. 

By the 1990s, new releases had slowed, with SolidWorks probably the most influential new arrival of the time. The 90s and 2000s saw a glut of [acquisition and consolidation activity](https://blog.fastwayengineering.com/cad-cae-timeline-history), with Siemens, Autodesk, and Dassault Systèmes scooping up many of the smaller players.

Through the 2010s, the most influential new products were probably Onshape and nTop. Onshape brought a modern, collaborative paradigm to the space, while nTop is the most prominent [implicit modelling](https://www.ntop.com/resources/blog/understanding-the-basics-of-b-reps-and-implicits/) system that I'm aware of. This period also saw the foundation of [shapr3d](https://www.shapr3d.com/), a much-lauded, modern CAD system that addresses the long-standing user hostility of incumbent CAD systems, while continuing to build on the Parasolid kernel's foundations.

![timeline-decade](/documentation-assets/why-i-joined-zoo/engineering_tools_by_decade.png)

Having traced the development of design tools, I think it's worth touching on the workflows these tools replaced...

### From paper, linen, and film...

Prior to the 1970s and the rise of CAD and CAE, 'design' really meant two things:

1. Thinking up concepts, exercising engineering judgement, and crunching numbers with a slide rule or a calculator to perform simplified analysis.
2. Producing, by hand, on paper, linen, or drafting film, detailed drawings of every single component in your system, with geometry, critical dimensions, and material selections dictated by the output of step 1.

This required teams of engineers educated in broadly the same way we are today; people who had studied structures and thermodynamics and materials science, and who were able to mathematically model the systems they were designing. It also required vast numbers of draftsmen, each hunched over a drawing board, producing meticulously detailed projections and cross sections of the components sketched out by their colleagues.

Changes required skillful use of an eraser, a knife, or a sponge and soapy water—but sometimes also mandated the production of a stack of amendments, or a complete redraw.

### To some of the most complex software ever built

Without question, CAD has revolutionized the practice of engineering. In the space of a couple of decades, draftsmen were deleted from the process almost entirely, with their role being absorbed into the expected skillset of a professional engineer. Drawings were no longer confined to physical and often fragile media, and no longer had to be painstakingly hand-crafted. Drawing changes became cheap and painless, and designs could be shared electronically.

The software that enabled this shift, our CAD and CAE tools, are some of the most intricate and sophisticated software systems ever created. A modern CAD system is a deeply challenging thing to build, requiring the input of actual subject matter experts in both mathematics and computer science. To represent the geometry of even the more simply shaped everyday objects around you, these software systems must be capable of implementing and applying complex mathematical operations to often incredibly large datasets.

Given that, our incumbent systems are already triumphs of human endeavor; the output of collaboration between computational geometers and systems programmers and engineers of several kinds. They let us iterate more quickly, explore more options, and push system performance more than ever before. 

### So why can't we make things like we used to?

This point is slightly facetious, as we clearly are capable of engineering more complex and more performant systems than ever before. 

For example, in civil aviation, the newest incarnations of high-bypass turbofan engines are incredible multidisciplinary accomplishments, pushing the limits of materials science, manufacturing technology, and computational simulation. Not only can they run for [5000 hours](https://aviationweek.com/mro/aircraft-propulsion/easa-expands-a380-trent-900-inspection-order) between inspection cycles, they do this while accommodating combustion temperatures that can be well [in excess of the melting point of all engine materials](https://www.theengineer.co.uk/content/news/tests-keep-turbines-running-above-blade-melting-point/). They also contain turbine blades that are the product of probably the most impressive manufacturing technique that I'm aware of: [single crystal casting](https://www.theengineer.co.uk/content/in-depth/jewel-in-the-crown-rolls-royce-s-single-crystal-turbine-blade-casting-foundry/).

Back on the ground, you are probably entirely familiar with how much better a modern car is than its equivalent predecessor vehicle was two decades ago. They are safer, faster, more comfortable, more refined, and [significantly more efficient](https://www.pewtrusts.org/en/research-and-analysis/fact-sheets/2011/04/20/driving-to-545-mpg-the-history-of-fuel-economy). It's easy to miss this broad-spectrum improvement in the quality of products around us because of that improvement's incrementally advancing nature, but this trend is evident almost everywhere. Sofas no longer burst into flames if you drop a cigarette on them, pocketable smartphones have more computing power than mainframe machines from a few decades ago, and doctors have access to [surgical robots](https://www.intuitive.com/en-us/products-and-services/da-vinci) that would be unimaginable to surgeons trained a generation prior.

However, in some respects, we really do seem to have gone backwards—particularly if we look at how long it takes us to bring new products into existence.

The now discontinued Airbus A380, one of the most recently developed major civil airframes, was first announced in 1990, but didn't take flight until 2005. In contrast, the North American Aviation P-51 Mustang prototype was designed and built in 120 days. Lockheed's SR-71 Blackbird, the fastest publicly acknowledged airbreathing manned aircraft ever, was designed by a team of around 200 engineers and first flew within around five years of its inception—and this extended well beyond the design of an airframe, encompassing the development of manufacturing techniques, materials, fuels, navigation systems, and extensive redevelopment of the Pratt & Whitney J58 powerplant.

In the civil space, the Empire State Building moved from initial concept to completed structure in just two years—planned and designed within six months, then constructed in just 14 months. On my side of the Atlantic, Crossrail was delivered more than [£4B over budget](https://www.railway-technology.com/features/timeline-crossrail-delays/), and five years late. In Germany, planning for the much-needed replacement for the ageing Schönefeld and Tegel airports began in 1992, but didn't actually open its doors to the public until 2020; [ten years late, and €5B over budget](https://www.euronews.com/2020/10/31/berlin-airport-opens-10-years-late-and-three-times-over-budget).

In many cases, this phenomenon can be at least partially attributed to a rising tide of regulatory requirements and increased expectations. Our professional antecedents would not have spent [£100M](https://www.bbc.co.uk/news/articles/c9wryxyljglo) on a bat tunnel. They would not have spent months or years consulting nearby residents or environmental groups, they didn't design vehicles to protect their occupants, and they were not subject to the same hardware and software certification processes that many industries face today. They also bundled test pilots into dangerous aircraft, strapped racing drivers into dangerous cars, and designed bridges that collapsed [less than a year after construction](https://en.wikipedia.org/wiki/Tacoma_Narrows_Bridge_(1940)).

So it is patently obvious that things are not 'worse' for no reason. As the saying goes, the rules of aviation safety are 'written in blood'—and I think the same could apply to many construction regulations, environmental regulations, and the driver and rider protections we now see in modern motor racing.

However, I don't think we can, in any degree of good faith, sit here and claim that the way in which we design and develop systems has no hand in the creeping drag on progress in industrialized societies.

## What can _we_ do better?

Despite the many benefits afforded by the last century's shift to digital engineering tools, it is not at all clear to me that we, the engineers, can actually ship production drawings for new systems any quicker than our grandfathers did. 

Why is this? Well, the impression I have is that much of the time saving offered, or at least touted, by digital transformation has been cannibalized by expansion of the work that we do. 

Before FEA and CFD, when the analysis methods involved lookup tables and crunching matrix math with a pen and a slide rule, there simply was no FEA<sup>†</sup> to do. By virtue of the analysis methods being organizationally expensive, i.e., taking your smartest people a long time to do, there existed a system that disincentivized small, marginal tweaks that would require everyone else to reconfigure their work. Instead, at least as far as I can tell from those who were there and who have written about it, numbers were worked out, fed to the draftsmen, and the parts were drawn up. The parts were then manufactured, tested, the results of the experiments assimilated and analyzed, and then maybe you went around the design-build-test loop again. This is a very straightforward process. It didn't require ruminating on software stacks or vendor integration—no need to worry about that when the tools of your trade are paper, pens, pencils, stencils, and your brain.

In contrast, contemporary design processes could now involve half a dozen different specialties, each with their own stack of specialist tools, putting forward their own priorities before anyone strikes a line on a (digital) page. As a result, even though we are now able produce a modification to a part's geometry and to communicate that with a machine shop in dramatically shorter order than fifty years ago, I don't think the first drawing from a clean sheet design really arrives any quicker... even if the product will likely perform better than the grandfather version.

Beyond bigger teams and a [Parkinson's Law](https://en.wikipedia.org/wiki/Parkinson%27s_law)-esque element of scope creep, I feel it is also worth considering the CAD systems specifically. Today’s CAD software, in large part, emulates its analog ancestors, mirroring workflows that were developed for drafting tables rather than networked supercomputers. Paraphrasing the thinking of a Twitter mutual, CAD really ought to stand for Computer Aided *Drawing*—because we're all still doing half the design work with Microsoft Excel or a notepad and a Casio pocket calculator. As for the other half, we're doing that with software systems which, despite their immense power and utility in the creation of complex geometries, have steep learning curves, a hostile user experience, poor interoperability, and which restrict computing hardware and operating system choices.

The fact that engineers spend so much time with these systems makes them, in my view, an obvious place to try and improve productivity, with today's CAD tools increasingly recognized as having a highly negative impact on [engineering productivity](https://static.sw.cdn.siemens.com/siemens-disw-assets/public/cPxmJwAR7g9v19xr2XGrR/en-US/LCI-Report-Siemens-CADUsability_tcm27-106492.pdf):

![productivity](/documentation-assets/why-i-joined-zoo/engineering_productivity_pie.png)

For context, in the simulation world, many tasks involve a degree of 'waiting around'. A simulation engineer could spend a couple of hours building a study that could take many hours to run, but while the model is running, the simulation engineer is freed up to do other value-added tasks. As a result, a marginal increase in solver performance, for example, may not actually be that valuable, as the engineer is not blocked from being productive while the simulation runs.

In contrast, in CAD land, the entire process is effectively bound by [user I/O](https://en.wikipedia.org/wiki/I/O_bound). CAD systems are highly interactive, requiring continuous real-time input and response from users in order to advance the design. This makes CAD systems a clear target for improvement, because the CAD user cannot do anything else productive while using their system. Any improvement, however marginal, to CAD productivity will be realized thousands and thousands of times.

----
<sup>†</sup> Technically, you could trace the origins of the finite element method back to the early 1940s, but I really mean something akin to 'before finite element tools for structural simulation were commonplace in engineering'.

### Mathematics doesn't rust... but the world around us has changed

I have no desire to disrespect the foundations of modern engineering software. Engineering software packages are tools, and the mathematics that underpins them does not rust. A boundary representation ([B-rep](https://en.wikipedia.org/wiki/Boundary_representation)) method does not become less useful because it was written in FORTRAN, or because it uses a programming paradigm we now consider old fashioned.

However, the way in which we use computers has changed dramatically since the 1970s. Each of us now has several machines, each of which is capable of sharing vast quantities of information with the other. Computer architecture itself has also changed. A typical CAD workstation today might have a 20 core CPU running at more than 5GHz, alongside a GPU that, although nominally intended for graphics, excels at performing large numbers of calculations in parallel. We use these machines to run software that was written for single-core, CPU-only systems.

I did not study Computer Science and have no formal training in computational geometry, so no warranty express or implied here, but my understanding is this:

- For B-reps, some common tasks in a CAD system are 'embarrassingly parallel', e.g., sampling curves, performing intersection checks. Others require largely sequential processing, e.g., graph-based operations on topology structures.
- For [NURBS](https://en.wikipedia.org/wiki/Non-uniform_rational_B-spline), evaluation of points and patches is amenable to parallelism, while [knot insertion](https://pages.mtu.edu/~shene/COURSES/cs3621/NOTES/spline/NURBS-knot-insert.html) and [degree elevation](https://pages.mtu.edu/~shene/COURSES/cs3621/LAB/surface/elevation.html) is not.
  - Finding the intersection of NURBS surfaces is computationally expensive, and would require surfaces to be broken into patches then merged if intersection tests were to be parallelized.
- For constructive solid geometry (CSG), where we need to perform repeated Boolean ops across a tree data structure, there is some opportunity to parallelize 'bounding volume hierarchies', but the speedup is likely to be bounded by the topological merge required to assemble a final boundary representation.

That is not nothing; while the overhead involved in moving data between CPU and GPU should not be ignored, some large portions of the CAD kernel's responsibilities do seem to be amenable to rearrangement to suit modern computer architectures.

#### On collaboration, file formats, and API access

The evolution of our surroundings is not limited to compute hardware.  There are three other areas I think we must improve, each of them related to the others.

With respect to collaboration, many CAD systems are inherently 'single player', but engineering is not. Now that our computers are all capable of communicating with one another, there is no reasonable case to made for why CAD systems should not offer some capacity for review and annotation/markup functionality that doesn't involve PowerPoint or a printer.

Proprietary file formats—perhaps by design—hinder automation, make elegant version control challenging, and limit extensibility. Similarly, my experience of CAD system APIs is almost entirely limited to restrictive and poorly documented VBScript support, with this functionality often only usable from within the CAD system itself.

Adoption of open file formats and improved API access would foster innovation in the space, allowing engineers to more readily develop and make use of new tools and automations.

### On bandwidth, input modes, and... 

So we have compute hardware that may allow for significant speed-up in core CAD operations. Unfortunately, that speedup is not much use if the speed of new geometry creation is typically limited by the user's ability to point and click fast enough. The bottleneck tends to lie in extracting design intent from the designer's brain, not in asking the CAD system to represent their geometry.

This is a problem of input bandwidth. At present, most CAD systems have only one input mode: the GUI. You point and click and punch in numbers, clicking thousands of times every day as you work from initial sketch to finished part. Sometimes, this is obviously the best input mode currently available to us. When you're sketching a shape that has a complex set of constraints defining the relationships between those elements, and where, say, the length of a line is dictated entirely by the geometry that surrounds it, this makes sense.

However, if I think of some simple geometry I might have frequently created during my stint as a designer, I am convinced that, for example, the point and click approach to creating a circle would be significantly slower than I could type `circle(x, y, radius)`. So which do you pick? Well, tools like [OpenSCAD](https://openscad.org/) exist for people who want purely programmatic geometry creation; everybody else has to point and click.

But what if you could have both? What if you could almost duplicitously interact with your geometry via a UI and a code editor? If the system was able to relate the underlying representation of an edge or a face to both a line in your code and the projection of that element on your screen. This would be the best of both worlds; we could point and click when that's the fastest method, and program when that's the fastest method, and by representing our geometry with code, we could build composable blocks that could be more than just a representation of geometry; they could be functional. We could build and share both our parts and functional macros in a file format you could open with any text editor, and which can be read by humans... *and machines*.

###  *The big pile of linear algebra*

In this instance, when I say machines, I mean the big pile of linear algebra:

![linear-algebra](/documentation-assets/why-i-joined-zoo/machine_learning.png)

```
Source: XKCD, https://xkcd.com/1838/
```

I am not convinced that LLMs are the path to artificial superintelligence, but they are capable of providing some impressive shortcuts in 'knowledge work'. For example, an LLM generated the skeleton code for the timeline visualization at the top of this article, and it did that in a fraction of the time it would take me to write that code manually. I was tweaking a functional baseline python script within ~60s, eliminating maybe 45 minutes of dull work pulling together some boilerplate plot code.

I think of this as effectively another input mode for interacting with the computer—I can give explicit instructions via commands and with my cursor, or I can give woolly commands to an LLM and ask it to fill in the blanks. This output would be utterly, and I mean _utterly_ useless if I were not able to go back and edit the code it had generated to fit my needs, but I can.

So, with code-based CAD and some appropriately knowledgeable folks steering the LLM, we can buy ourselves another input mode. We now have three:

- GUI.
- Code.
- Natural language via AI.

With three input modes, the design bottleneck may no longer lie in getting design intent from the user. If that bottleneck can be eliminated, or even reduced, then, all of a sudden, the time domain performance of your CAD kernel becomes very important. 

Further, to do a good job with natural language driven input, the generated geometry needs to 'look' as if it were created by a person; we want a part that has a full feature tree and that can be interactively modified. In this way, we can use natural language input as a means of accelerating human-guided product development; not as a pipe-dream promise of automating the design process.

## Why I'm excited about Zoo

### Hard problems and smart people

This is a statement of the obvious, but building a new CAD system is hard. There is a good reason that most commercial CAD systems are built on Parasolid or ACIS. However, to achieve Zoo's goals, I think there is legitimate need to build a new kernel. We might be choosing the hard path here, but when hard problems are actually worth attacking, this is a good thing. Hard problems are how you keep the brightest minds engaged.

The team is also stacked with smart people. I am not a credentialist, but it is comforting to see names like Silicon Graphics, Google, Microsoft, Cloudflare, Ansys, Northrop Grumman—and The White House—amongst the backgrounds of your colleagues. Thankfully, my experience with the team so far has routinely left me feeling like the dumbest person in the room, providing all the supporting evidence I need that these people are legit.

### Domain expertise and the structure of the universe

I touched on this a little above, but the both the generative AI and the 'hardware' spaces are foamy targets for investors right now. Unfortunately, many of the companies I've seen move into this space seem to have fairly rudimentary understanding of its vast, complex, and relatively high-capability nature. Companies promising that they can generate CAD from natural language, but whose products produce polygonal mesh by tying an open source project to an OpenAI endpoint, either simply do not understand the requirements of real engineering teams—or they're cynically riding a hype cycle with no legitimate desire to address customer need.

At the risk of sounding combative, an STL file is not really CAD: it can't be driven parametrically, and it can't be used to produce manufacturing drawings. For your product to have any prospect of being useful to real engineers who engage with real manufacturing techniques, where engineers are actually providing real GD&T and real drawings, your system must be capable of generating a B-rep<sup>†</sup> format one way or another.

Because the team at Zoo has real, lived experience of design and manufacture in-house, this sort of thing is understood throughout the company. In the few weeks I've been with team, I have seen software teams not only battle with the structure of the universe, fighting some of the hardest problems in computational geometry, but also corral the mechanical engineers we have on staff and press them for feedback, seeking understanding of thought patterns, workflows, and common frustrations with their former CAD systems of choice.

They get it.

----
<sup>†</sup>I appreciate that implicits appear to be legitimately useful, but I haven't seen mesh to solid model conversion. I don't actually know how you would deal with something like a bearing pocket that exists in an implicit model.

### Work worth doing

This is effectively a rephrasing of [Why our design tools matter](#why-our-design-tools-matter), but I very sincerely believe that we need better, more open, and easier to use tools in engineering. We are surrounded by machines with incredible capabilities, and we simply aren't making the most of them.

Engineers craft the world, and I can think of few things I'd rather dedicate my time to more than supporting them to do just that—make better use of each other's technology to do a better job, faster, and with less frustration. 



